@INPROCEEDINGS{he2022elic,
    author={He, Dailan and Yang, Ziming and Peng, Weikun and Ma, Rui and Qin, Hongwei and Wang, Yan},
    booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={ELIC: Efficient Learned Image Compression with Unevenly Grouped Space-Channel Contextual Adaptive Coding}, 
    year={2022},
    volume={},
    number={},
    pages={5708-5717},
    keywords={Adaptation models;Computer vision;Image coding;Computational modeling;Transforms;Computer architecture;Decoding;Low-level vision},
    doi={10.1109/CVPR52688.2022.00563}
}


@INPROCEEDINGS{xu2024manifoundation,
    author={Xu, Zhixuan and Gao, Chongkai and Liu, Zixuan and Yang, Gang and Tie, Chenrui and Zheng, Haozhuo and Zhou, Haoyu and Peng, Weikun and Wang, Debang and Hu, Tianrun and Chen, Tianyi and Yu, Zhouliang and Shao, Lin},
    booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
    title={ManiFoundation Model for General-Purpose Robotic Manipulation of Contact Synthesis with Arbitrary Objects and Robots}, 
    year={2024},
    volume={},
    number={},
    pages={10905-10912},
    keywords={Point cloud compression;Foundation models;Pressing;Manipulators;Distance measurement;Robots;Intelligent robots;Videos},
    doi={10.1109/IROS58592.2024.10801782}
}


@InProceedings{peng2024tiebot,
    title = 	 {TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach},
    author =       {Peng, Weikun and Lv, Jun and Zeng, Yuwei and Chen, Haonan and Zhao, Siheng and Sun, Jichen and Lu, Cewu and Shao, Lin},
    booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
    pages = 	 {318--339},
    year = 	 {2024},
    editor = 	 {Agrawal, Pulkit and Kroemer, Oliver and Burgard, Wolfram},
    volume = 	 {270},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {06--09 Nov},
    publisher =    {PMLR},
    pdf = 	 {https://raw.githubusercontent.com/mlresearch/v270/main/assets/peng25a/peng25a.pdf},
    url = 	 {https://proceedings.mlr.press/v270/peng25a.html},
    abstract = 	 {The tie-knotting task is highly challenging due to the tie’s high deformation and long-horizon manipulation actions. This work presents TieBot, a Real-to-Sim-to-Real learning from visual demonstration system for the robots to learn to knot a tie. We introduce the Hierarchical Feature Matching approach to estimate a sequence of tie’s meshes from the demonstration video. With these estimated meshes used as subgoals, we first learn a teacher policy using privileged information. Then, we learn a student policy with point cloud observation by imitating teacher policy. Lastly, our pipeline applies learned policy to real-world execution. We demonstrate the effectiveness of TieBot in simulation and the real world. In the real-world experiment, a dual-arm robot successfully knots a tie, achieving 50% success rate among 10 trials. Videos can be found on https://tiebots.github.io/.}
}

@article{peng2025videoarticulation,
    Author = {Weikun Peng and Jun Lv and Cewu Lu and Manolis Savva},
    Title = {Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos},
    Year = {2025},
    eprint={2506.08334},
    archivePrefix={arXiv},
    primaryClass={cs.GR}
}